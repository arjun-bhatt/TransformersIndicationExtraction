{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformers Indication Extraction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SbZvgF0vvru",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "879f3d69-062a-4803-d41a-b19dc285bce9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85a3iUFNv-mT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd /content/drive/My Drive/FDA Things/BioBert/biobert"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GGlnSmOBA8d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S70K1jnO1Dd9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! CUDA_LAUNCH_BLOCKING=\"1\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAZzL9fEzfPj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brki_mtizNFN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Function to calculate area under the curve, helper function for training & eval\n",
        "def get_AUC(preds, labels):\n",
        "\n",
        "    flat_master_preds = [item for sublist in preds for item in sublist]\n",
        "    flat_master_truth = [item for sublist in labels for item in sublist]\n",
        "\n",
        "    std_preds = [x[1] - x[0] for x in flat_master_preds]\n",
        "    res = roc_auc_score(flat_master_truth, std_preds)\n",
        "    return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cQNvaZ9bnyy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Functions to calculate the accuracy of our predictions vs labels, helper functions for training and eval\n",
        "\n",
        "# Supports drugbank\n",
        "def flat_accuracy(preds, labels, DrugBank=False):\n",
        "    # print('got these as inputs:\\n\\n', 'preds:', preds, '\\nlabels:', labels)\n",
        "    condensed_preds = []\n",
        "    for subl in preds:\n",
        "        if subl[0] > subl[1]:\n",
        "          condensed_preds.append(0)\n",
        "        else:\n",
        "          condensed_preds.append(1)\n",
        "\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "\n",
        "    if not DrugBank:\n",
        "      tn, fp, fn, tp = confusion_matrix(labels, condensed_preds).ravel()    \n",
        "      return [np.sum(pred_flat == labels_flat) / len(labels_flat), tp, fp, tn, fn]\n",
        "\n",
        "    if DrugBank:\n",
        "      return [np.sum(pred_flat == labels_flat) / len(labels_flat)]\n",
        "\n",
        "# Used for joint_model\n",
        "def binary_acc(y_pred, y_test):\n",
        "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
        "\n",
        "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
        "    acc = correct_results_sum/y_test.shape[0]\n",
        "    acc = torch.round(acc * 100)\n",
        "    \n",
        "    return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PIiVlDYCtSq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_model_info(model):\n",
        "    # Get all of the model's parameters as a list of tuples.\n",
        "    params = list(model.named_parameters())\n",
        "    print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "    print('==== Embedding Layer ====\\n')\n",
        "\n",
        "    for p in params[0:5]:\n",
        "        print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "    print('\\n==== First Transformer ====\\n')\n",
        "    \n",
        "    for p in params[5:21]:\n",
        "        print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "    for p in params[-20:-4]:\n",
        "        print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "    print('\\n==== Output Layer ====\\n')\n",
        "    for p in params[-4:]:\n",
        "        print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpt6tR83keZD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYsV4H8fCpZ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def environment_setup(verbose = False, PATH=\"/content/drive/My Drive/FDA Things/paranoia4_no_commas.csv\"):\n",
        "\n",
        "    \"\"\"\n",
        "    Parses Data from a .csv file.\n",
        "    \n",
        "    Returns:::\n",
        "    train_sentences: 1d np array of length 6195\n",
        "    train_labels: 1d np array of length 6195\n",
        "    test_sentences: 1d np array of length 1549\n",
        "    test_labels: 1d np array of length 1549\n",
        "    device: torch.device\n",
        "    \"\"\"\n",
        "\n",
        "    # If there's a GPU available...\n",
        "    if torch.cuda.is_available():    \n",
        "\n",
        "        # Tell PyTorch to use the GPU.    \n",
        "        device = torch.device(\"cuda\")\n",
        "\n",
        "        if verbose:\n",
        "            print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "            print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "    # If not...\n",
        "    else:\n",
        "        if verbose: print('No GPU available, using the CPU instead.')\n",
        "        device = torch.device(\"cpu\")\n",
        "\n",
        "    # Opting for binary classification instead of multi-class classification\n",
        "    data = pd.read_csv(PATH)\n",
        "    data = data[data.columns[-3:]].copy() # removing all the extraneous numbers\n",
        "    clean_data = pd.DataFrame({'text': data.iloc[:,1], 'label': data.iloc[:,2]})\n",
        "    clean_data = clean_data.replace(to_replace={'u': 0, '4': 0, '3': 0, '/': 0, 'c': 0, '2': 0, '1': 1, '0': 0, '': 0}, value=None)\n",
        "    clean_data = clean_data.fillna(0)\n",
        "\n",
        "\n",
        "    # making sure data\n",
        "    clean_data.astype({'label': 'int'}).dtypes\n",
        "    train_df, eval_df = train_test_split(clean_data, test_size=0.2)\n",
        "    train_df.iloc[:,1] = train_df.iloc[:,1].astype('int64')\n",
        "\n",
        "    eval_df.iloc[:,1] = eval_df.iloc[:,1].astype('int64')\n",
        "    eval_df = eval_df.astype(str)\n",
        "    eval_df['label'] = eval_df['label'].astype(int)\n",
        "\n",
        "    # Report the number of sentences.\n",
        "    if verbose:\n",
        "        print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "    train_sentences = train_df.text.values\n",
        "    train_labels = train_df.label.values\n",
        "\n",
        "    test_sentences = eval_df.text.values\n",
        "    test_labels = eval_df.label.values\n",
        "\n",
        "    return train_sentences, train_labels, test_sentences, test_labels, device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6RJ8xXqllss",
        "colab_type": "text"
      },
      "source": [
        "# DIVIDING LINE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kG-lwjwGCLud",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler\n",
        "import copy\n",
        "\n",
        "def tokenize_and_organize_data(tokenizer, sentences, labels, verbose=False, max_sentence_length=64, BATCH_SIZE=32):\n",
        "\n",
        "    \"\"\"\n",
        "    Produces a dataloader from a tokenizer, sentences, and labels.\n",
        "\n",
        "    Parameters:::\n",
        "    tokenizer: Tokenizer object (e.g. transformers.tokenization_distilbert.DistilBertTokenizer object)\n",
        "    sentences: 1d np array\n",
        "    labels: 1d np array\n",
        "\n",
        "    Returns:::\n",
        "    train_sentences: 1d np array of length .8*sentences\n",
        "    train_labels: 1d np array of length .8*sentences\n",
        "    test_sentences: 1d np array of length .2*sentences\n",
        "    test_labels: 1d np array of length .2*sentences\n",
        "    device: torch.device\n",
        "    \"\"\"\n",
        "\n",
        "    if verbose:\n",
        "        # Print the original sentence.\n",
        "        print(' Original: ', sentences[0])\n",
        "\n",
        "        # Print the sentence split into tokens.\n",
        "        print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "        # Print the sentence mapped to token ids.\n",
        "        print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))\n",
        "\n",
        "    # Tokenize all of the sentences and map the tokens to their word IDs.\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    # For every sentence...\n",
        "    for sent in sentences:\n",
        "        # `encode_plus` will:\n",
        "        #   (1) Tokenize the sentence.\n",
        "        #   (2) Prepend the `[CLS]` token to the start.\n",
        "        #   (3) Append the `[SEP]` token to the end.\n",
        "        #   (4) Map tokens to their IDs.\n",
        "        #   (5) Pad or truncate the sentence to `max_length`\n",
        "        #   (6) Create attention masks for [PAD] tokens.\n",
        "        sent = str(sent)\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "                            sent,                      # Sentence to encode.\n",
        "                            add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                            max_length = max_sentence_length,           # Pad & truncate all sentences.\n",
        "                            truncation = True,\n",
        "                            pad_to_max_length = True,\n",
        "                            return_attention_mask = True,   # Construct attn. masks.\n",
        "                            return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                      )\n",
        "        \n",
        "        # Add the encoded sentence to the list.    \n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "        \n",
        "        # And its attention mask (simply differentiates padding from non-padding).\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "    # Convert the lists into tensors.\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "    labels = torch.tensor(labels)\n",
        "\n",
        "    if verbose:\n",
        "        # Print sentence 0, now as a list of IDs.\n",
        "        print('Original: ', sentences[0])\n",
        "        print('Token IDs:', input_ids[0])\n",
        "\n",
        "    # Combine the training inputs into a TensorDataset.\n",
        "    dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "    # The DataLoader needs to know our batch size for training, so we specify it \n",
        "    # here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "    # size of 16 or 32.\n",
        "    batch_size = BATCH_SIZE\n",
        "\n",
        "    # We'll take training samples in random order. \n",
        "    dataloader = DataLoader(\n",
        "                dataset,  # The training samples.\n",
        "                sampler = RandomSampler(dataset), # Select batches randomly\n",
        "                batch_size = batch_size # Trains with this batch size.\n",
        "            )\n",
        "    \n",
        "    return dataloader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e23rrt1XE0UJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup, AdamW\n",
        "\n",
        "\n",
        "def load_model(model, epochs, train_dataloader):\n",
        "\n",
        "    \"\"\"\n",
        "    Produces object to aid in the model's training.\n",
        "\n",
        "    Parameters:::\n",
        "    model: some transformers model (e.g. <class 'transformers.modeling_distilbert.DistilBertForSequenceClassification'>)\n",
        "    train_dataloader: a pytorch dataloader \n",
        "\n",
        "    Returns:::\n",
        "    scheduler: torch.optim.lr_scheduler.LambdaLR object\n",
        "    optimizer: transformers.optimization.AdamW object\n",
        "    \"\"\"\n",
        "\n",
        "    model = model.cuda()\n",
        "    print_model_info(model)\n",
        "\n",
        "    # Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "    # I believe the 'W' stands for 'Weight Decay fix\"\n",
        "    optimizer = AdamW(model.parameters(),\n",
        "                      lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                      eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                    )\n",
        "\n",
        "    # Total number of training steps is [number of batches] x [number of epochs]. \n",
        "    # (Note that this is not the same as the number of training samples).\n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "    # Create the learning rate scheduler.\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                                num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                                num_training_steps = total_steps)\n",
        "    \n",
        "    return scheduler, optimizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6J-FYdx6nFE_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def train_model(model, epochs, train_dataloader, validation_dataloader, scheduler, optimizer, device, seed_val = 42):\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    Trains the model & evaluates every epoch.\n",
        "\n",
        "    Parameters:::\n",
        "    [self-explanatory]\n",
        "\n",
        "    Returns:::\n",
        "    flat_master_preds: a list of logit outputs\n",
        "    model: the trained model\n",
        "    flat_master_truth: a list of length 0.8*sentences of integers\n",
        "    hidden_states: a list of length 0.8*sentences/batch size, where each element is a torch.Tensor of size [batch size, features]\n",
        "    \"\"\"\n",
        "\n",
        "    # This training code is based on the `run_glue.py` script here:\n",
        "    # https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "    # Set the seed value all over the place to make this reproducible.\n",
        "\n",
        "    random.seed(seed_val)\n",
        "    np.random.seed(seed_val)\n",
        "    torch.manual_seed(seed_val)\n",
        "    torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "    # We'll store a number of quantities such as training and validation loss, \n",
        "    # validation accuracy, and timings.\n",
        "    training_stats = []\n",
        "\n",
        "    # Measure the total training time for the whole run.\n",
        "    total_t0 = time.time()\n",
        "\n",
        "    # For each epoch...\n",
        "    for epoch_i in range(0, epochs):\n",
        "        \n",
        "        # ========================================\n",
        "        #               Training\n",
        "        # ========================================\n",
        "        \n",
        "        # Perform one full pass over the training set.\n",
        "\n",
        "        print(\"\")\n",
        "        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "        print('Training...')\n",
        "\n",
        "        # Measure how long the training epoch takes.\n",
        "        t0 = time.time()\n",
        "\n",
        "        # Reset the total loss for this epoch.\n",
        "        total_train_loss = 0\n",
        "\n",
        "        # Put the model into training mode. Don't be mislead--the call to \n",
        "        # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "        # `dropout` and `batchnorm` layers behave differently during training\n",
        "        # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "        model.train()\n",
        "\n",
        "        # For each batch of training data...\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            # print('step:', step, '\\n\\nbatch is a', type(batch), 'of length ', len(batch), 'where each element is ', batch[0].shape, \"\\n\\n\")\n",
        "\n",
        "            # Progress update every 40 batches.\n",
        "            if step % 40 == 0 and not step == 0:\n",
        "                \n",
        "                # Calculate elapsed time in minutes.\n",
        "                elapsed = format_time(time.time() - t0)\n",
        "                \n",
        "                # Report progress.\n",
        "                print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "            # Unpack this training batch from our dataloader. \n",
        "            #\n",
        "            # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "            # `to` method.\n",
        "            #\n",
        "            # `batch` contains three pytorch tensors:\n",
        "            #   [0]: input ids \n",
        "            #   [1]: attention masks\n",
        "            #   [2]: labels \n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "            b_labels = batch[2]\n",
        "            b_labels = b_labels.long()\n",
        "            b_labels = b_labels.to(device)\n",
        "            \n",
        "            # Always clear any previously calculated gradients before performing a\n",
        "            # backward pass. PyTorch doesn't do this automatically because \n",
        "            # accumulating the gradients is \"convenient while training RNNs\". \n",
        "            # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "            model.zero_grad()        \n",
        "\n",
        "            # Perform a forward pass (evaluate the model on this training batch).\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # It returns different numbers of parameters depending on what arguments\n",
        "            # arge given and what flags are set. For our useage here, it returns\n",
        "            # the loss (because we provided labels) and the \"logits\"--the model\n",
        "            # outputs prior to activation.\n",
        "\n",
        "            # Some models don't play well with token_type_ids; you may need to comment/uncomment the next two lines as needed.\n",
        "\n",
        "            # loss, logits, _ = model(b_input_ids, \n",
        "            #                     token_type_ids=None, \n",
        "            #                     attention_mask=b_input_mask,\n",
        "            #                     labels=b_labels)\n",
        "            \n",
        "            loss, logits, _ = model(b_input_ids, \n",
        "                                attention_mask=b_input_mask,\n",
        "                                labels=b_labels)\n",
        "\n",
        "            # Accumulate the training loss over all of the batches so that we can\n",
        "            # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "            # single value; the `.item()` function just returns the Python value \n",
        "            # from the tensor.\n",
        "            total_train_loss += loss.item()\n",
        "\n",
        "            # Perform a backward pass to calculate the gradients.\n",
        "            loss.backward()\n",
        "\n",
        "            # Clip the norm of the gradients to 1.0.\n",
        "            # This is to help prevent the \"exploding gradients\" problem.\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # Update parameters and take a step using the computed gradient.\n",
        "            # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "            # modified based on their gradients, the learning rate, etc.\n",
        "            optimizer.step()\n",
        "\n",
        "            # Update the learning rate.\n",
        "            scheduler.step()\n",
        "\n",
        "\n",
        "        # Calculate the average loss over all of the batches.\n",
        "        avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "        \n",
        "        # Measure how long this epoch took.\n",
        "        training_time = format_time(time.time() - t0)\n",
        "\n",
        "        print(\"\")\n",
        "        print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "        print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "            \n",
        "        # ========================================\n",
        "        #               Validation\n",
        "        # ========================================\n",
        "        # After the completion of each training epoch, measure our performance on\n",
        "        # our validation set.\n",
        "\n",
        "        print(\"\")\n",
        "        print(\"Running Validation...\")\n",
        "\n",
        "        t0 = time.time()\n",
        "\n",
        "        # Put the model in evaluation mode--the dropout layers behave differently\n",
        "        # during evaluation.\n",
        "        model.eval()\n",
        "\n",
        "        # Tracking variables \n",
        "        total_eval_accuracy = 0\n",
        "        total_eval_loss = 0\n",
        "        nb_eval_steps = 0\n",
        "        tn = 0\n",
        "        fp = 0\n",
        "        fn = 0\n",
        "        tp = 0\n",
        "        master_preds = []\n",
        "        master_truth = []\n",
        "        hidden_state_list = []\n",
        "\n",
        "        # Evaluate data for one epoch\n",
        "        for batch in validation_dataloader:\n",
        "            \n",
        "            # Unpack this training batch from our dataloader. \n",
        "            #\n",
        "            # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "            # the `to` method.\n",
        "            #\n",
        "            # `batch` contains three pytorch tensors:\n",
        "            #   [0]: input ids \n",
        "            #   [1]: attention masks\n",
        "            #   [2]: labels \n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "            b_labels = batch[2].long().to(device)\n",
        "            \n",
        "            # Tell pytorch not to bother with constructing the compute graph during\n",
        "            # the forward pass, since this is only needed for backprop (training).\n",
        "            with torch.no_grad():        \n",
        "\n",
        "                # Forward pass, calculate logit predictions.\n",
        "                # token_type_ids is the same as the \"segment ids\", which \n",
        "                # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "                # The documentation for this `model` function is here: \n",
        "                # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "                # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "                # values prior to applying an activation function like the softmax.\n",
        "\n",
        "\n",
        "\n",
        "                # Same situation as before; model.forward sometimes dislikes a token_type_ids depending on the model\n",
        "\n",
        "                # loss, logits, hidden_states = model(b_input_ids, \n",
        "                #                       token_type_ids=None, \n",
        "                #                       attention_mask=b_input_mask,\n",
        "                #                       labels=b_labels)\n",
        "                \n",
        "                loss, logits, hidden_states = model(b_input_ids, \n",
        "                                      attention_mask=b_input_mask,\n",
        "                                      labels=b_labels)\n",
        "\n",
        "            # Accumulate the validation loss.\n",
        "            total_eval_loss += loss.item()\n",
        "\n",
        "            # Move logits and labels to CPU\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "            master_preds.append(logits)\n",
        "            master_truth.append(label_ids)\n",
        "            # print('hidden_states is a tuple of size: ', len(hidden_states), ' where each entry has shape: ', hidden_states[len(hidden_states) - 1].shape, '. We are adding this slice of that to our hidden state list', hidden_states[len(hidden_states) - 1][:,0,:].shape)\n",
        "            hidden_state_list.append(hidden_states[len(hidden_states) - 1][:,0,:])\n",
        "            # Calculate the accuracy for this batch of test sentences, and\n",
        "            # accumulate it over all batches.\n",
        "\n",
        "            flat_acc_res = flat_accuracy(logits, label_ids)\n",
        "            total_eval_accuracy += flat_acc_res[0]\n",
        "            tp += flat_acc_res[1]\n",
        "            fp += flat_acc_res[2]\n",
        "            tn += flat_acc_res[3]\n",
        "            fn += flat_acc_res[4]\n",
        "            \n",
        "\n",
        "        # Report the final accuracy for this validation run.\n",
        "        avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "        print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "        # Calculate the average loss over all of the batches.\n",
        "        avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "        \n",
        "        # Measure how long the validation run took.\n",
        "        validation_time = format_time(time.time() - t0)\n",
        "        \n",
        "        print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "        print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "        print('Confusion matrix::: \\n', 'tp: ', tp, 'fp: ', fp, 'tn: ', tn, 'fn: ', fn)\n",
        "        print(get_AUC(master_preds, master_truth))\n",
        "\n",
        "        # Record all statistics from this epoch.\n",
        "        training_stats.append(\n",
        "            {\n",
        "                'epoch': epoch_i + 1,\n",
        "                'Training Loss': avg_train_loss,\n",
        "                'Valid. Loss': avg_val_loss,\n",
        "                'Valid. Accur.': avg_val_accuracy,\n",
        "                'Training Time': training_time,\n",
        "                'Validation Time': validation_time\n",
        "            }\n",
        "        )\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Training complete!\")\n",
        "\n",
        "    print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n",
        "\n",
        "    # ----------\n",
        "\n",
        "    # Display floats with two decimal places.\n",
        "    pd.set_option('precision', 2)\n",
        "\n",
        "    # Create a DataFrame from our training statistics.\n",
        "    df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "    # Use the 'epoch' as the row index.\n",
        "    df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "    # Display the table.\n",
        "    print(df_stats)\n",
        "\n",
        "    flat_pred_list = [item for sublist in master_preds for item in sublist]\n",
        "    flat_master_truth = [item for sublist in master_truth for item in sublist]\n",
        "    # print('final input embeddings:\\n\\n', model.get_input_embeddings()) # included here for ease of adapting this code\n",
        "\n",
        "    return flat_pred_list, flat_master_truth, model, hidden_state_list\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72VCFKPqTlya",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def just_eval_model(model, validation_dataloader, device='cpu', debug=False, AUC=False, drugBank=False):\n",
        "\n",
        "\n",
        "        \"\"\"\n",
        "        Evaluates the model.\n",
        "\n",
        "        Parameters:::\n",
        "        [self-explanatory]\n",
        "\n",
        "        Returns:::\n",
        "        flat_pred_list: a list of logit outputs\n",
        "        flat_master_truth: a list of length 0.8*sentences of integers\n",
        "        hidden_states_list: a list of length 0.8*sentences/batch size, where each element is a torch.Tensor of size [batch size, features]\n",
        "        \"\"\"\n",
        "\n",
        "        print(\"\")\n",
        "        print(\"Running Validation...\")\n",
        "\n",
        "        # Put the model in evaluation mode--the dropout layers behave differently\n",
        "        # during evaluation.\n",
        "        model = model.to(device).eval()\n",
        "\n",
        "        # Tracking variables \n",
        "        total_eval_accuracy = 0\n",
        "        total_eval_loss = 0\n",
        "        nb_eval_steps = 0\n",
        "        tn = 0\n",
        "        fp = 0\n",
        "        fn = 0\n",
        "        tp = 0\n",
        "        master_preds = []\n",
        "        master_truth = []\n",
        "        hidden_states_list = []\n",
        "\n",
        "        # Evaluate data for one epoch\n",
        "        for batch in validation_dataloader:\n",
        "            \n",
        "            # Unpack this training batch from our dataloader. \n",
        "            #\n",
        "            # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "            # the `to` method.\n",
        "            #\n",
        "            # `batch` contains three pytorch tensors:\n",
        "            #   [0]: input ids \n",
        "            #   [1]: attention masks\n",
        "            #   [2]: labels \n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "            b_labels = batch[2].to(device)\n",
        "            if debug:\n",
        "              print('b_labels shape:', b_labels.shape)\n",
        "              print('b_input shape:', b_input_ids.shape)\n",
        "              print('b_input mask shape:', b_input_mask.shape)\n",
        "            \n",
        "            # Tell pytorch not to bother with constructing the compute graph during\n",
        "            # the forward pass, since this is only needed for backprop (training).\n",
        "            with torch.no_grad():        \n",
        "\n",
        "                # Forward pass, calculate logit predictions.\n",
        "                # token_type_ids is the same as the \"segment ids\", which \n",
        "                # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "                # The documentation for this `model` function is here: \n",
        "                # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "                # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "                # values prior to applying an activation function like the softmax.\n",
        "                loss, logits, hidden_states = model(b_input_ids, \n",
        "                                      attention_mask=b_input_mask,\n",
        "                                      labels=b_labels)\n",
        "                \n",
        "            # Accumulate the validation loss.\n",
        "            total_eval_loss += loss.item()\n",
        "\n",
        "            # Move logits and labels to CPU\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "            master_preds.append(logits)\n",
        "            master_truth.append(label_ids)\n",
        "\n",
        "            # some fancy indexing to get the vectors associated with the [CLS] token for the last layer\n",
        "            hidden_states_list.append(hidden_states[len(hidden_states) - 1][:,0,:])\n",
        "\n",
        "            # Calculate the accuracy for this batch of test sentences, and\n",
        "            # accumulate it over all batches.\n",
        "            \n",
        "            flat_acc_res = flat_accuracy(logits, label_ids, drugBank)\n",
        "            total_eval_accuracy += flat_acc_res[0]\n",
        "\n",
        "\n",
        "            if not drugBank:\n",
        "              tp += flat_acc_res[1]\n",
        "              fp += flat_acc_res[2]\n",
        "              tn += flat_acc_res[3]\n",
        "              fn += flat_acc_res[4]\n",
        "              \n",
        "\n",
        "        # Report the final accuracy for this validation run.\n",
        "        avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "        print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "        # Calculate the average loss over all of the batches.\n",
        "        avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "                \n",
        "        print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "\n",
        "        if not drugBank: print('Confusion matrix::: \\n', 'tp: ', tp, 'fp: ', fp, 'tn: ', tn, 'fn: ', fn)\n",
        "        if AUC: print(get_AUC(master_preds, master_truth))\n",
        "\n",
        "        print(\"\")\n",
        "        print(\"Testing complete!\")\n",
        "\n",
        "        flat_pred_list = [item for sublist in master_preds for item in sublist]\n",
        "        flat_master_truth = [item for sublist in master_truth for item in sublist]\n",
        "        return flat_pred_list, flat_master_truth, hidden_states_list\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27RVOwvaIacj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import BertTokenizer, AutoTokenizer, AlbertTokenizer, DistilBertTokenizer\n",
        "from transformers import BertForSequenceClassification, AutoModelWithLMHead, RobertaConfig, BertForMaskedLM, BertConfig, AlbertForSequenceClassification, RobertaForSequenceClassification, DistilBertForSequenceClassification\n",
        "\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\", do_lower_case=True)\n",
        "tokenizer2 = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)\n",
        "\n",
        "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", output_hidden_states=True)\n",
        "model2 = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", output_hidden_states=True)\n",
        "\n",
        "epochs = 1\n",
        "epochs2 = 1\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UkeC7SG2krJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_sentences, train_labels, test_sentences, test_labels, device = environment_setup()\n",
        "train_dataloader = tokenize_and_organize_data(tokenizer, train_sentences, train_labels)\n",
        "validation_dataloader = tokenize_and_organize_data(tokenizer, test_sentences, test_labels)\n",
        "scheduler, optimizer = load_model(model, epochs, train_dataloader)\n",
        "# passing in train_dataloader twice to evaluate on the training set every epoch\n",
        "_, flat_master_truth, trained_model, hidden_states = train_model(model, epochs, train_dataloader, train_dataloader, scheduler, optimizer, device)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-fUqbQwJYzp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "train_dataloader2 = tokenize_and_organize_data(tokenizer, train_sentences, train_labels)\n",
        "validation_dataloader2 = tokenize_and_organize_data(tokenizer, test_sentences, test_labels)\n",
        "scheduler2, optimizer2 = load_model(model2, epochs2, train_dataloader2)\n",
        "_, flat_master_truth2, trained_model2, hidden_states2 = train_model(model2, epochs2, train_dataloader2, train_dataloader2, scheduler2, optimizer2, device)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GA8MVUgo_tT_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "flat_hidden_states = [item for sublist in hidden_states for item in sublist]\n",
        "flat_hidden_states2 = [item for sublist in hidden_states2 for item in sublist]\n",
        "\n",
        "# so NOW, each element of the list is a sentence vector (so flat_hidden_states is a list of 1d tensors of size [features])\n",
        "# and flat_master_truth is a list that has corresponding labels\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYCyOrn9_Pl9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# t-SNE business\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "def plot_tSNE(data, truths, start=0, amt=2000):\n",
        "\n",
        "  \"\"\"\n",
        "  Constructs a tSNE plot.\n",
        "\n",
        "  Parameters:::\n",
        "  Kind of picky for data type. \n",
        "  \n",
        "  data: a list of length 0.8*sentences, where each element is a list of length [features]\n",
        "  truths: a list of the same length, where each element is an integer\n",
        "\n",
        "  These next parameters are to reduce computation time (~7000 vectors of ~750 elements takes quite a while)\n",
        "  start: at what point in the outermost list to start counting points for the tSNE\n",
        "  amt: the number of points to include\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  new_array = np.array(data)\n",
        "  tsne = TSNE(n_components=2, random_state=0)\n",
        "  y = truths[start:(start+amt)]\n",
        "  data_X = new_array[start:(start+amt)]\n",
        "  tsne_obj= tsne.fit_transform(data_X)\n",
        "  tsne_df = pd.DataFrame({'X':tsne_obj[:,0],\n",
        "                        'Y':tsne_obj[:,1],\n",
        "                        'label':y})\n",
        "\n",
        "  sns.scatterplot(x=\"X\", y=\"Y\",\n",
        "              hue=\"label\",\n",
        "              palette=['red','blue'],\n",
        "              legend='full',\n",
        "              data=tsne_df);\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-w4fIZjAFuR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "array_hidden_states = []\n",
        "for i in flat_hidden_states:\n",
        "  array_hidden_states.append(list(i))\n",
        "\n",
        "array_hidden_states2 = []\n",
        "for i in flat_hidden_states2:\n",
        "  array_hidden_states2.append(list(i))\n",
        "\n",
        "\n",
        "plot_tSNE(array_hidden_states, flat_master_truth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B52t-QjRAY49",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_tSNE(array_hidden_states2, flat_master_truth2, 2000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bfe5GMEP2SQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# So now, we take our hidden states extracted from each model, and stack them together. \n",
        "# joined_lists is an np array of length 0.8*sentences, where each element is another np array of length 2, where each element of that inner array is a tensor of size [features]\n",
        "\n",
        "joined_lists = np.column_stack([flat_hidden_states, flat_hidden_states2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddGNbq45_aMp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reformatting the data into new_list, which is a list of length 0.8*sentences where each element is an array of size [features from model1 + features from model2]\n",
        "\n",
        "for ix,iy in np.ndindex(joined_lists.shape):\n",
        "  joined_lists[ix,iy] = joined_lists[ix, iy].tolist()\n",
        "\n",
        "new_list = []\n",
        "for i in joined_lists:\n",
        "  new_list.append(i[0] + i[1]) # confirmed this is joining those two tensors, not elementwise adding them"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTcI3SzFPzp_",
        "colab_type": "text"
      },
      "source": [
        "# Your model's training starts here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPpyXvawZTKA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "EPOCHS = 1\n",
        "BATCH_SIZE = 64\n",
        "LEARNING_RATE = 0.001\n",
        "\n",
        "# Training another model on top of the internal representations of the previous 2 individual models\n",
        "class trainData(Dataset):\n",
        "    def __init__(self, X_data, y_data):\n",
        "        self.X_data = X_data\n",
        "        self.y_data = y_data    \n",
        "    def __getitem__(self, index):\n",
        "        return self.X_data[index], self.y_data[index]\n",
        "    def __len__ (self):\n",
        "        return len(self.X_data)\n",
        "\n",
        "train_data = trainData(torch.FloatTensor(new_list), \n",
        "                       torch.FloatTensor(flat_master_truth))\n",
        "\n",
        "\n",
        "# Preparing a test dataset for evaluation (currently just the training dataset again, so we can evaluate on the training)\n",
        "class testData(Dataset):    \n",
        "    def __init__(self, X_data):\n",
        "        self.X_data = X_data\n",
        "    def __getitem__(self, index):\n",
        "        return self.X_data[index]\n",
        "    def __len__ (self):\n",
        "        return len(self.X_data)\n",
        "    \n",
        "test_data = testData(torch.FloatTensor(new_list))\n",
        "\n",
        "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_data, batch_size=1) \n",
        "y_test = flat_master_truth"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PO5p3AnQcSZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This block of code is getting the internal representations of each model for the test set\n",
        "# Also allows for evaluation of each model individually at this point\n",
        "\n",
        "# Step 1: Get dataloader for test set\n",
        "test_dataloader = tokenize_and_organize_data(tokenizer, test_sentences, test_labels, verbose=False)\n",
        "\n",
        "# Step 2: From that dataloader, make predictions based on our previously trained two individual models\n",
        "_, test_flat_master_truth_list, test_hidden_states_list = just_eval_model(trained_model, test_dataloader, 'cuda')\n",
        "_, _, test_hidden_states_list2 = just_eval_model(trained_model2, test_dataloader, 'cuda')\n",
        "\n",
        "# Step 2b: Go through the same process of putting our data in the right format\n",
        "test_flat_hidden_states = [item for sublist in test_hidden_states_list for item in sublist]\n",
        "test_flat_hidden_states2 = [item for sublist in test_hidden_states_list2 for item in sublist]\n",
        "\n",
        "test_joined_lists = np.column_stack([test_flat_hidden_states, test_flat_hidden_states2]) # np.column_stack([flat_pred_list, flat_pred_list2])\n",
        "\n",
        "for ix,iy in np.ndindex(test_joined_lists.shape):\n",
        "  test_joined_lists[ix,iy] = test_joined_lists[ix, iy].tolist()\n",
        "\n",
        "test_new_list = []\n",
        "for i in test_joined_lists:\n",
        "  test_new_list.append(i[0] + i[1])\n",
        "\n",
        "# Step 3: Now put that test data into a Dataset, then a DataLoader\n",
        "\n",
        "actual_test_data = testData(torch.FloatTensor(test_new_list))\n",
        "actual_test_loader = DataLoader(dataset=actual_test_data, batch_size=1) \n",
        "y_actual_test = test_flat_master_truth_list\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mf7_5vWweepz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "# Defining our neural network\n",
        "\n",
        "class binaryClassification(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(binaryClassification, self).__init__()\n",
        "        # Number of input features is 1536 = 2*[features]\n",
        "        \n",
        "        self.const1 = 1536\n",
        "        self.layer_1 = nn.Linear(1536, self.const1) \n",
        "        self.layer_2 = nn.Linear(int(self.const1), int(self.const1/2))\n",
        "        self.layer_3 = nn.Linear(int(self.const1/2), int(self.const1/4))\n",
        "        self.layer_4 = nn.Linear(int(self.const1/4), int(self.const1/8))\n",
        "        self.layer_5 = nn.Linear(int(self.const1/8), int(self.const1/16))\n",
        "        self.layer_out = nn.Linear(int(self.const1/16), int(1))\n",
        "\n",
        "        self.relu = nn.LeakyReLU()\n",
        "        self.dropout = nn.Dropout(p=0.25)\n",
        "\n",
        "        self.batchnorm1 = nn.BatchNorm1d(self.const1)\n",
        "        self.batchnorm2 = nn.BatchNorm1d(int(self.const1/2))\n",
        "        self.batchnorm3 = nn.BatchNorm1d(int(self.const1/4))\n",
        "        self.batchnorm4 = nn.BatchNorm1d(int(self.const1/8))\n",
        "        self.batchnorm5 = nn.BatchNorm1d(int(self.const1/16))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        x = self.relu(self.layer_1(inputs))\n",
        "        x = self.batchnorm1(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.relu(self.layer_2(x))\n",
        "        x = self.batchnorm2(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.relu(self.layer_3(x))\n",
        "        x = self.batchnorm3(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.relu(self.layer_4(x))\n",
        "        x = self.batchnorm4(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.relu(self.layer_5(x))\n",
        "        x = self.batchnorm5(x)\n",
        "        x = self.layer_out(x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVs1IZZ-zN99",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining how the model should learn\n",
        "\n",
        "joint_model = binaryClassification()\n",
        "joint_model.to(device)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.AdamW(joint_model.parameters(), lr=LEARNING_RATE) # trying Adam, Adagrad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lj5A5RV-zyB9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Testing the joint model\n",
        "\n",
        "def test_on_train(joint_model, test_loader):\n",
        "    y_pred_list = []\n",
        "    joint_model = joint_model.eval()\n",
        "    with torch.no_grad():\n",
        "        for X_batch in test_loader:\n",
        "            X_batch = X_batch.to(device)\n",
        "            y_test_pred = joint_model(X_batch).to(device)\n",
        "            y_test_pred = torch.sigmoid(y_test_pred)\n",
        "            y_pred_tag = torch.round(y_test_pred)\n",
        "            y_pred_list.append(y_pred_tag.cpu().numpy())\n",
        "\n",
        "    y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
        "    print('TEST ON TRAIN:::')\n",
        "    print(confusion_matrix(y_test, y_pred_list))\n",
        "    print(classification_report(y_test, y_pred_list))\n",
        "\n",
        "\n",
        "def test_joint_model(joint_model, actual_test_loader, drugBank=False):\n",
        "    y_pred_list_test = []\n",
        "    joint_model = joint_model.eval()\n",
        "    with torch.no_grad():\n",
        "        for X_batch in actual_test_loader:\n",
        "            X_batch = X_batch.to(device)\n",
        "            y_test_pred = joint_model(X_batch).to(device)\n",
        "            y_test_pred = torch.sigmoid(y_test_pred)\n",
        "            y_pred_tag = torch.round(y_test_pred)\n",
        "            y_pred_list_test.append(y_pred_tag.cpu().numpy())\n",
        "\n",
        "    y_pred_list_test = [a.squeeze().tolist() for a in y_pred_list_test]\n",
        "\n",
        "    print('--------------------------------------------------\\n On Actual Test Set:')\n",
        "    if not drugBank: print(confusion_matrix(y_actual_test, y_pred_list_test))\n",
        "\n",
        "    print(classification_report(y_actual_test, y_pred_list_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcN44TrFzkFo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "joint_model.train()\n",
        "for e in range(1, EPOCHS+1):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        y_pred = joint_model(X_batch)\n",
        "        \n",
        "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
        "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "\n",
        "    print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')\n",
        "    test_on_train(joint_model, test_loader)\n",
        "    test_joint_model(joint_model, actual_test_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZByi06o6ekz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = 'cuda'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwqStSvWCeFw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('and now a t-SNE for our joint model:')\n",
        "plot_tSNE(test_new_list, test_flat_master_truth_list, 0, 1548)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UUo1puj36WT",
        "colab_type": "text"
      },
      "source": [
        "Now going through the same process for DrugBank indications."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsRZKtn1eHa1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drug_bank_df = pd.read_csv('/content/drive/My Drive/FDA Things/drugbank-indication.tsv', sep='\\t') \n",
        "clean_drug_bank_df = pd.concat([drug_bank_df[drug_bank_df.columns[-1]], pd.Series([1 for i in range(len(drug_bank_df[drug_bank_df.columns[-1]]))])], axis=1).dropna()\n",
        "clean_drug_bank_df = clean_drug_bank_df.rename({\"indication\":\"text\", 0:\"label\"})\n",
        "clean_drug_bank_df.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlR9vGC7gpn1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drug_bank_dataloader = tokenize_and_organize_data(tokenizer, clean_drug_bank_df.indication, clean_drug_bank_df[clean_drug_bank_df.columns[-1]].tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qa30xbrgvCP8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "db_flat_pred_list, db_flat_master_truth, db_hidden_states_list = just_eval_model(model, drug_bank_dataloader, device='cuda', drugBank=True)\n",
        "db_flat_pred_list2, _, db_hidden_states_list2 = just_eval_model(model2, drug_bank_dataloader, device='cuda', drugBank=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xj0wILoJdsY9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "db_test_flat_hidden_states = [item for sublist in db_hidden_states_list for item in sublist]\n",
        "db_test_flat_hidden_states2 = [item for sublist in db_hidden_states_list2 for item in sublist]\n",
        "\n",
        "db_test_joined_lists = np.column_stack([db_test_flat_hidden_states, db_test_flat_hidden_states2]) # np.column_stack([flat_pred_list, flat_pred_list2])\n",
        "print(db_test_joined_lists[1, 1].shape)\n",
        "\n",
        "for ix,iy in np.ndindex(db_test_joined_lists.shape):\n",
        "  db_test_joined_lists[ix,iy] = db_test_joined_lists[ix, iy].tolist()\n",
        "\n",
        "db_test_new_list = []\n",
        "for i in db_test_joined_lists:\n",
        "  db_test_new_list.append(i[0] + i[1])\n",
        "\n",
        "db_actual_test_data = testData(torch.FloatTensor(db_test_new_list))\n",
        "\n",
        "db_actual_test_loader = DataLoader(dataset=db_actual_test_data, batch_size=1) \n",
        "y_actual_test = db_flat_master_truth\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7gyN5-teRQj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_joint_model(joint_model, db_actual_test_loader, drugBank=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wIznWzIdzhV",
        "colab_type": "text"
      },
      "source": [
        "# Results History"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyQ4_6x9cvxM",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Joint model:\n",
        "```\n",
        "[[666  46]\n",
        " [ 42 795]]\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.94      0.94      0.94       712\n",
        "           1       0.95      0.95      0.95       837\n",
        "\n",
        "    accuracy                           0.94      1549\n",
        "   macro avg       0.94      0.94      0.94      1549\n",
        "weighted avg       0.94      0.94      0.94      1549\n",
        "```\n",
        "\n",
        "First individual model:\n",
        "\n",
        "```\n",
        "Running Validation...\n",
        "  Accuracy: 0.94\n",
        "  Validation Loss: 0.50\n",
        "Confusion matrix::: \n",
        " tp:  795 fp:  47 tn:  665 fn:  42\n",
        "0.9745143839018432\n",
        "\n",
        "Testing complete!\n",
        "```\n",
        "\n",
        "Second individual model:\n",
        "\n",
        "```\n",
        "Running Validation...\n",
        "  Accuracy: 0.92\n",
        "  Validation Loss: 0.40\n",
        "Confusion matrix::: \n",
        " tp:  781 fp:  64 tn:  648 fn:  56\n",
        "0.9685842965110816\n",
        "\n",
        "Testing complete!\n",
        "```\n",
        "\n",
        "\n",
        "-----------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylw4Yv0SxXAS",
        "colab_type": "text"
      },
      "source": [
        "These are the first results I got. \n",
        "```\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.93      0.74      0.82       738\n",
        "           1       0.80      0.95      0.87       811\n",
        "\n",
        "    accuracy                           0.85      1549\n",
        "\n",
        "   macro avg       0.87      0.84      0.85      1549\n",
        "weighted avg       0.86      0.85      0.85      1549\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "The second model performed very poorly on the test set, so I suspect it's not learning properly. Results for that second model are below.\n",
        "\n",
        "```\n",
        "Running Validation...\n",
        "  Accuracy: 0.48\n",
        "  Validation Loss: 2.24\n",
        "Confusion matrix::: \n",
        " tp:  64 fp:  54 tn:  684 fn:  747\n",
        "0.5564511008858546\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "I made changes, and future runs showed accuracy of 0.92 to 0.93 for both models individually on the test set, which is in line with what I'd expect. The training for my model, however, went to 1.00 accuracy, and the test set results were worse than the ones above. This made me think my model either wasn't learning properly or I wasn't evaluating the learning properly. I changed a few things and now training accuracy no longer starts at 1 and improves as expected, but the performance for the joint model continues to be worse than either model on its own. I suspect I'm overfitting, as the model does fairly well on the training set but poorly on the test set. I tried some hyperparameter tuning to stop overfitting, but from those trials I realized I really wasn't overfitting and it just seems my model is unable to learn a lot from the training set.\n"
      ]
    }
  ]
}